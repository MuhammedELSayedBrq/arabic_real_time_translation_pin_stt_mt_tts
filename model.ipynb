{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and install whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/openai/whisper.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:09.000]  Hello Hello 1,2,3 I'm talking now to test Wesber's accuracy. Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Angry Nerd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "!whisper \"_assets/whisper_test.wav\" --model medium.en --output_dir \"_assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
      "               [--output_dir OUTPUT_DIR]\n",
      "               [--output_format {txt,vtt,srt,tsv,json,all}]\n",
      "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
      "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
      "               [--temperature TEMPERATURE] [--best_of BEST_OF]\n",
      "               [--beam_size BEAM_SIZE] [--patience PATIENCE]\n",
      "               [--length_penalty LENGTH_PENALTY]\n",
      "               [--suppress_tokens SUPPRESS_TOKENS]\n",
      "               [--initial_prompt INITIAL_PROMPT]\n",
      "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
      "               [--fp16 FP16]\n",
      "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
      "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
      "               [--logprob_threshold LOGPROB_THRESHOLD]\n",
      "               [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
      "               [--word_timestamps WORD_TIMESTAMPS]\n",
      "               [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
      "               [--append_punctuations APPEND_PUNCTUATIONS]\n",
      "               [--highlight_words HIGHLIGHT_WORDS]\n",
      "               [--max_line_width MAX_LINE_WIDTH]\n",
      "               [--max_line_count MAX_LINE_COUNT]\n",
      "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
      "               [--clip_timestamps CLIP_TIMESTAMPS]\n",
      "               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n",
      "               audio [audio ...]\n",
      "\n",
      "positional arguments:\n",
      "  audio                 audio file(s) to transcribe\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         name of the Whisper model to use (default: small)\n",
      "  --model_dir MODEL_DIR\n",
      "                        the path to save model files; uses ~/.cache/whisper by\n",
      "                        default (default: None)\n",
      "  --device DEVICE       device to use for PyTorch inference (default: cpu)\n",
      "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
      "                        directory to save the outputs (default: .)\n",
      "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
      "                        format of the output file; if not specified, all\n",
      "                        available formats will be produced (default: all)\n",
      "  --verbose VERBOSE     whether to print out the progress and debug messages\n",
      "                        (default: True)\n",
      "  --task {transcribe,translate}\n",
      "                        whether to perform X->X speech recognition\n",
      "                        ('transcribe') or X->English translation ('translate')\n",
      "                        (default: transcribe)\n",
      "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
      "                        language spoken in the audio, specify None to perform\n",
      "                        language detection (default: None)\n",
      "  --temperature TEMPERATURE\n",
      "                        temperature to use for sampling (default: 0)\n",
      "  --best_of BEST_OF     number of candidates when sampling with non-zero\n",
      "                        temperature (default: 5)\n",
      "  --beam_size BEAM_SIZE\n",
      "                        number of beams in beam search, only applicable when\n",
      "                        temperature is zero (default: 5)\n",
      "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
      "                        https://arxiv.org/abs/2204.05424, the default (1.0) is\n",
      "                        equivalent to conventional beam search (default: None)\n",
      "  --length_penalty LENGTH_PENALTY\n",
      "                        optional token length penalty coefficient (alpha) as\n",
      "                        in https://arxiv.org/abs/1609.08144, uses simple\n",
      "                        length normalization by default (default: None)\n",
      "  --suppress_tokens SUPPRESS_TOKENS\n",
      "                        comma-separated list of token ids to suppress during\n",
      "                        sampling; '-1' will suppress most special characters\n",
      "                        except common punctuations (default: -1)\n",
      "  --initial_prompt INITIAL_PROMPT\n",
      "                        optional text to provide as a prompt for the first\n",
      "                        window. (default: None)\n",
      "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
      "                        if True, provide the previous output of the model as a\n",
      "                        prompt for the next window; disabling may make the\n",
      "                        text inconsistent across windows, but the model\n",
      "                        becomes less prone to getting stuck in a failure loop\n",
      "                        (default: True)\n",
      "  --fp16 FP16           whether to perform inference in fp16; True by default\n",
      "                        (default: True)\n",
      "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
      "                        temperature to increase when falling back when the\n",
      "                        decoding fails to meet either of the thresholds below\n",
      "                        (default: 0.2)\n",
      "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
      "                        if the gzip compression ratio is higher than this\n",
      "                        value, treat the decoding as failed (default: 2.4)\n",
      "  --logprob_threshold LOGPROB_THRESHOLD\n",
      "                        if the average log probability is lower than this\n",
      "                        value, treat the decoding as failed (default: -1.0)\n",
      "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
      "                        if the probability of the <|nospeech|> token is higher\n",
      "                        than this value AND the decoding has failed due to\n",
      "                        `logprob_threshold`, consider the segment as silence\n",
      "                        (default: 0.6)\n",
      "  --word_timestamps WORD_TIMESTAMPS\n",
      "                        (experimental) extract word-level timestamps and\n",
      "                        refine the results based on them (default: False)\n",
      "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
      "                        if word_timestamps is True, merge these punctuation\n",
      "                        symbols with the next word (default: \"'“¿([{-)\n",
      "  --append_punctuations APPEND_PUNCTUATIONS\n",
      "                        if word_timestamps is True, merge these punctuation\n",
      "                        symbols with the previous word (default:\n",
      "                        \"'.。,，!！?？:：”)]}、)\n",
      "  --highlight_words HIGHLIGHT_WORDS\n",
      "                        (requires --word_timestamps True) underline each word\n",
      "                        as it is spoken in srt and vtt (default: False)\n",
      "  --max_line_width MAX_LINE_WIDTH\n",
      "                        (requires --word_timestamps True) the maximum number\n",
      "                        of characters in a line before breaking the line\n",
      "                        (default: None)\n",
      "  --max_line_count MAX_LINE_COUNT\n",
      "                        (requires --word_timestamps True) the maximum number\n",
      "                        of lines in a segment (default: None)\n",
      "  --max_words_per_line MAX_WORDS_PER_LINE\n",
      "                        (requires --word_timestamps True, no effect with\n",
      "                        --max_line_width) the maximum number of words in a\n",
      "                        segment (default: None)\n",
      "  --threads THREADS     number of threads used by torch for CPU inference;\n",
      "                        supercedes MKL_NUM_THREADS/OMP_NUM_THREADS (default:\n",
      "                        0)\n",
      "  --clip_timestamps CLIP_TIMESTAMPS\n",
      "                        comma-separated list start,end,start,end,...\n",
      "                        timestamps (in seconds) of clips to process, where the\n",
      "                        last end timestamp defaults to the end of the file\n",
      "                        (default: 0)\n",
      "  --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD\n",
      "                        (requires --word_timestamps True) skip silent periods\n",
      "                        longer than this threshold (in seconds) when a\n",
      "                        possible hallucination is detected (default: None)\n"
     ]
    }
   ],
   "source": [
    "!whisper -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double click on next cell to see whisper help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
    "               [--output_dir OUTPUT_DIR]\n",
    "               [--output_format {txt,vtt,srt,tsv,json,all}]\n",
    "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
    "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
    "               [--temperature TEMPERATURE] [--best_of BEST_OF]\n",
    "               [--beam_size BEAM_SIZE] [--patience PATIENCE]\n",
    "               [--length_penalty LENGTH_PENALTY]\n",
    "               [--suppress_tokens SUPPRESS_TOKENS]\n",
    "               [--initial_prompt INITIAL_PROMPT]\n",
    "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
    "               [--fp16 FP16]\n",
    "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
    "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
    "               [--logprob_threshold LOGPROB_THRESHOLD]\n",
    "               [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
    "               [--word_timestamps WORD_TIMESTAMPS]\n",
    "               [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
    "               [--append_punctuations APPEND_PUNCTUATIONS]\n",
    "               [--highlight_words HIGHLIGHT_WORDS]\n",
    "               [--max_line_width MAX_LINE_WIDTH]\n",
    "               [--max_line_count MAX_LINE_COUNT]\n",
    "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
    "               [--clip_timestamps CLIP_TIMESTAMPS]\n",
    "               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n",
    "               audio [audio ...]\n",
    "\n",
    "positional arguments:\n",
    "  audio                 audio file(s) to transcribe\n",
    "\n",
    "options:\n",
    "  -h, --help            show this help message and exit\n",
    "  --model MODEL         name of the Whisper model to use (default: small)\n",
    "  --model_dir MODEL_DIR\n",
    "                        the path to save model files; uses ~/.cache/whisper by\n",
    "                        default (default: None)\n",
    "  --device DEVICE       device to use for PyTorch inference (default: cpu)\n",
    "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
    "                        directory to save the outputs (default: .)\n",
    "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
    "                        format of the output file; if not specified, all\n",
    "                        available formats will be produced (default: all)\n",
    "  --verbose VERBOSE     whether to print out the progress and debug messages\n",
    "                        (default: True)\n",
    "  --task {transcribe,translate}\n",
    "                        whether to perform X->X speech recognition\n",
    "                        ('transcribe') or X->English translation ('translate')\n",
    "                        (default: transcribe)\n",
    "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
    "                        language spoken in the audio, specify None to perform\n",
    "                        language detection (default: None)\n",
    "  --temperature TEMPERATURE\n",
    "                        temperature to use for sampling (default: 0)\n",
    "  --best_of BEST_OF     number of candidates when sampling with non-zero\n",
    "                        temperature (default: 5)\n",
    "  --beam_size BEAM_SIZE\n",
    "                        number of beams in beam search, only applicable when\n",
    "                        temperature is zero (default: 5)\n",
    "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
    "                        https://arxiv.org/abs/2204.05424, the default (1.0) is\n",
    "                        equivalent to conventional beam search (default: None)\n",
    "  --length_penalty LENGTH_PENALTY\n",
    "                        optional token length penalty coefficient (alpha) as\n",
    "                        in https://arxiv.org/abs/1609.08144, uses simple\n",
    "                        length normalization by default (default: None)\n",
    "  --suppress_tokens SUPPRESS_TOKENS\n",
    "                        comma-separated list of token ids to suppress during\n",
    "                        sampling; '-1' will suppress most special characters\n",
    "                        except common punctuations (default: -1)\n",
    "  --initial_prompt INITIAL_PROMPT\n",
    "                        optional text to provide as a prompt for the first\n",
    "                        window. (default: None)\n",
    "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
    "                        if True, provide the previous output of the model as a\n",
    "                        prompt for the next window; disabling may make the\n",
    "                        text inconsistent across windows, but the model\n",
    "                        becomes less prone to getting stuck in a failure loop\n",
    "                        (default: True)\n",
    "  --fp16 FP16           whether to perform inference in fp16; True by default\n",
    "                        (default: True)\n",
    "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
    "                        temperature to increase when falling back when the\n",
    "                        decoding fails to meet either of the thresholds below\n",
    "                        (default: 0.2)\n",
    "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
    "                        if the gzip compression ratio is higher than this\n",
    "                        value, treat the decoding as failed (default: 2.4)\n",
    "  --logprob_threshold LOGPROB_THRESHOLD\n",
    "                        if the average log probability is lower than this\n",
    "                        value, treat the decoding as failed (default: -1.0)\n",
    "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
    "                        if the probability of the <|nospeech|> token is higher\n",
    "                        than this value AND the decoding has failed due to\n",
    "                        `logprob_threshold`, consider the segment as silence\n",
    "                        (default: 0.6)\n",
    "  --word_timestamps WORD_TIMESTAMPS\n",
    "                        (experimental) extract word-level timestamps and\n",
    "                        refine the results based on them (default: False)\n",
    "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
    "                        if word_timestamps is True, merge these punctuation\n",
    "                        symbols with the next word (default: \"'“¿([{-)\n",
    "  --append_punctuations APPEND_PUNCTUATIONS\n",
    "                        if word_timestamps is True, merge these punctuation\n",
    "                        symbols with the previous word (default:\n",
    "                        \"'.。,，!！?？:：”)]}、)\n",
    "  --highlight_words HIGHLIGHT_WORDS\n",
    "                        (requires --word_timestamps True) underline each word\n",
    "                        as it is spoken in srt and vtt (default: False)\n",
    "  --max_line_width MAX_LINE_WIDTH\n",
    "                        (requires --word_timestamps True) the maximum number\n",
    "                        of characters in a line before breaking the line\n",
    "                        (default: None)\n",
    "  --max_line_count MAX_LINE_COUNT\n",
    "                        (requires --word_timestamps True) the maximum number\n",
    "                        of lines in a segment (default: None)\n",
    "  --max_words_per_line MAX_WORDS_PER_LINE\n",
    "                        (requires --word_timestamps True, no effect with\n",
    "                        --max_line_width) the maximum number of words in a\n",
    "                        segment (default: None)\n",
    "  --threads THREADS     number of threads used by torch for CPU inference;\n",
    "                        supercedes MKL_NUM_THREADS/OMP_NUM_THREADS (default:\n",
    "                        0)\n",
    "  --clip_timestamps CLIP_TIMESTAMPS\n",
    "                        comma-separated list start,end,start,end,...\n",
    "                        timestamps (in seconds) of clips to process, where the\n",
    "                        last end timestamp defaults to the end of the file\n",
    "                        (default: 0)\n",
    "  --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD\n",
    "                        (requires --word_timestamps True) skip silent periods\n",
    "                        longer than this threshold (in seconds) when a\n",
    "                        possible hallucination is detected (default: None)\n",
    "[00:00.000 --> 00:09.000]  Hello Hello 1,2,3 I'm talking now to test Wesber's accuracy. Thank you.\n",
    "c:\\Users\\Angry Nerd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
    "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
